---
title: '量子位发表了文章: 港大北航等1bit大模型引热议，IEEE刊物评“解决AI能源需求”！作者亲自解读在此'
date: '2024-06-09'
linkTitle: https://zhuanlan.zhihu.com/p/702474838
source: 量子位的知乎动态
description: <blockquote data-pid="T-diyGIu">BiLLM团队 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p
  data-pid="atNUk_d3">极限量化，<b>把每个参数占用空间压缩到1.1bit</b>！</p><p data-pid="-kE2sMOJ">IEEE
  Spectrum专栏，一种名为<b>BiLLM</b>的训练后量化（PTQ）方法火了。</p><p data-pid="iEjclf9m">通俗来讲，随着LLM参数规模越来越大，模型计算的内存和资源也面临着更大的挑战。<b>如何把模型变得小巧经济实惠，能塞进手机等设备中？</b></p><p
  data-pid="XxLDDpy6">BiLLM解决的正是这样的一个问题。它使用1bit来近似网络中的大多数参数，使用2bit来表示一些对性能最有影响的权重。</p><p
  class="ztext-empty-paragraph"><br></p><figure data-size="normal"><img src="https://pic1.zhimg.c
  ...
disable_comments: true
---
<blockquote data-pid="T-diyGIu">BiLLM团队 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p data-pid="atNUk_d3">极限量化，<b>把每个参数占用空间压缩到1.1bit</b>！</p><p data-pid="-kE2sMOJ">IEEE Spectrum专栏，一种名为<b>BiLLM</b>的训练后量化（PTQ）方法火了。</p><p data-pid="iEjclf9m">通俗来讲，随着LLM参数规模越来越大，模型计算的内存和资源也面临着更大的挑战。<b>如何把模型变得小巧经济实惠，能塞进手机等设备中？</b></p><p data-pid="XxLDDpy6">BiLLM解决的正是这样的一个问题。它使用1bit来近似网络中的大多数参数，使用2bit来表示一些对性能最有影响的权重。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><img src="https://pic1.zhimg.c ...