---
title: '量子位发表了文章: 新架构RNN反超Transformer：每个隐藏状态都是一个模型，一作：从根本上改变语言模型'
date: '2024-07-09'
linkTitle: https://zhuanlan.zhihu.com/p/707839672
source: 量子位的知乎动态
description: <blockquote data-pid="DWqkDGAp">梦晨 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p
  data-pid="qzgwtUpy">新架构，再次向Transformer发起挑战！</p><p data-pid="lpiB_bfF">核心思想：<b>将RNN中的隐藏状态换成可学习的模型</b>。</p><p
  data-pid="AEbR_1B9">甚至<b>在测试时都可以学习</b>，所以该方法称为<b>TTT</b>（Test-Time Training）。</p><p
  data-pid="i1t-yUGR">共同一作UC伯克利的Karen Dalal表示：我相信这将<b>从根本上改变语言模型</b>。</p><figure data-size="normal"><img
  src="https://pic4.zhimg.com/v2-49be8ee4e86ada407afc2aefcff2d7b3.jpg" data-caption=""
  data-size="normal" data-rawwidth="640" ...
disable_comments: true
---
<blockquote data-pid="DWqkDGAp">梦晨 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p data-pid="qzgwtUpy">新架构，再次向Transformer发起挑战！</p><p data-pid="lpiB_bfF">核心思想：<b>将RNN中的隐藏状态换成可学习的模型</b>。</p><p data-pid="AEbR_1B9">甚至<b>在测试时都可以学习</b>，所以该方法称为<b>TTT</b>（Test-Time Training）。</p><p data-pid="i1t-yUGR">共同一作UC伯克利的Karen Dalal表示：我相信这将<b>从根本上改变语言模型</b>。</p><figure data-size="normal"><img src="https://pic4.zhimg.com/v2-49be8ee4e86ada407afc2aefcff2d7b3.jpg" data-caption="" data-size="normal" data-rawwidth="640" ...