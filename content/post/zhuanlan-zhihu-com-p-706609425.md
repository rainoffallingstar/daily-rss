---
title: '量子位发表了文章: 只需将感知推理能力拆分，2B大模型就能战胜20B！国产新框架高效处理视觉任务'
date: '2024-07-02'
linkTitle: https://zhuanlan.zhihu.com/p/706609425
source: 量子位的知乎动态
description: <h3>Prism团队 投稿至 凹非寺<br>量子位 | 公众号 QbitAI</h3><p data-pid="Yr4XDhqj">只要把推理和感知能力拆分，2B大模型就能战胜20B？！</p><p
  data-pid="-3Oj0VqK">上海AI Lab联合南京大学、香港中文大学等机构，共同推出了一套两阶段框架——<b>Prism</b>。</p><p data-pid="-_L8xBCN">这一框架不仅显式地解耦了视觉语言模型（VLM）
  的感知和推理，还提供了一种更高效的处理视觉语言任务的方案。</p><p class="ztext-empty-paragraph"><br></p><figure
  data-size="normal"><img src="https://pic3.zhimg.com/v2-9236b11121b95bdb8e5ef416e02f6c16.jpg"
  data-caption="" data-size="normal" data-rawwidth="824" data-rawheight="728" ...
disable_comments: true
---
<h3>Prism团队 投稿至 凹非寺<br>量子位 | 公众号 QbitAI</h3><p data-pid="Yr4XDhqj">只要把推理和感知能力拆分，2B大模型就能战胜20B？！</p><p data-pid="-3Oj0VqK">上海AI Lab联合南京大学、香港中文大学等机构，共同推出了一套两阶段框架——<b>Prism</b>。</p><p data-pid="-_L8xBCN">这一框架不仅显式地解耦了视觉语言模型（VLM） 的感知和推理，还提供了一种更高效的处理视觉语言任务的方案。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-9236b11121b95bdb8e5ef416e02f6c16.jpg" data-caption="" data-size="normal" data-rawwidth="824" data-rawheight="728" ...