---
title: A future role for health applications of large language models depends on regulators
  enforcing safety standards
date: '2024-08-23'
linkTitle: https://pubmed.ncbi.nlm.nih.gov/39179311/?utm_source=curl&utm_medium=rss&utm_campaign=pubmed-2&utm_content=1FakS-2QOkCT8HsMOQP1bCRQ4YzyumYOmxmF0moLsQ3dFB1E9V&fc=20220326224207&ff=20240824182422&v=2.18.0.post9+e462414
source: heidelberg[Affiliation]
description: Among the rapid integration of artificial intelligence in clinical settings,
  large language models (LLMs), such as Generative Pre-trained Transformer-4, have
  emerged as multifaceted tools that have potential for health-care delivery, diagnosis,
  and patient care. However, deployment of LLMs raises substantial regulatory and
  safety concerns. Due to their high output variability, poor inherent explainability,
  and the risk of so-called AI hallucinations, LLM-based health-care applications
  that ...
disable_comments: true
---
Among the rapid integration of artificial intelligence in clinical settings, large language models (LLMs), such as Generative Pre-trained Transformer-4, have emerged as multifaceted tools that have potential for health-care delivery, diagnosis, and patient care. However, deployment of LLMs raises substantial regulatory and safety concerns. Due to their high output variability, poor inherent explainability, and the risk of so-called AI hallucinations, LLM-based health-care applications that ...