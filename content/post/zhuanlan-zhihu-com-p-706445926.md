---
title: '量子位发表了文章: 拆分Transformer注意力，韩国团队让大模型解码提速20倍'
date: '2024-07-01'
linkTitle: https://zhuanlan.zhihu.com/p/706445926
source: 量子位的知乎动态
description: <blockquote data-pid="MnYg76Rs">克雷西 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p
  data-pid="RBFlqo28">只要将注意力切块，就能让大模型解码提速20倍。</p><p data-pid="4JAKPeU2">来自韩国科学技术研究院、LG和DeepMind的研究人员，提出了一种新的Transformer架构。</p><p
  data-pid="oEQcFxVE">不仅获得了更快的推理速度，内存开销也大幅度下降。</p><figure data-size="normal"><img
  src="https://pic3.zhimg.com/v2-c8ed85d0f0b7de917569aca8e65da15a.jpg" data-caption=""
  data-size="normal" data-rawwidth="1080" data-rawheight="466" class="origin_image
  zh-lightbox-thumb" ...
disable_comments: true
---
<blockquote data-pid="MnYg76Rs">克雷西 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p data-pid="RBFlqo28">只要将注意力切块，就能让大模型解码提速20倍。</p><p data-pid="4JAKPeU2">来自韩国科学技术研究院、LG和DeepMind的研究人员，提出了一种新的Transformer架构。</p><p data-pid="oEQcFxVE">不仅获得了更快的推理速度，内存开销也大幅度下降。</p><figure data-size="normal"><img src="https://pic3.zhimg.com/v2-c8ed85d0f0b7de917569aca8e65da15a.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="466" class="origin_image zh-lightbox-thumb" ...