---
title: Medical large language models are susceptible to targeted misinformation attacks
date: '2024-10-24'
linkTitle: https://pubmed.ncbi.nlm.nih.gov/39443664/?utm_source=curl&utm_medium=rss&utm_campaign=pubmed-2&utm_content=1FakS-2QOkCT8HsMOQP1bCRQ4YzyumYOmxmF0moLsQ3dFB1E9V&fc=20220326224207&ff=20241024201603&v=2.18.0.post9+e462414
source: heidelberg[Affiliation]
description: Large language models (LLMs) have broad medical knowledge and can reason
  about medical information across many domains, holding promising potential for diverse
  medical applications in the near future. In this study, we demonstrate a concerning
  vulnerability of LLMs in medicine. Through targeted manipulation of just 1.1% of
  the weights of the LLM, we can deliberately inject incorrect biomedical facts. The
  erroneous information is then propagated in the model's output while maintaining
  ...
disable_comments: true
---
Large language models (LLMs) have broad medical knowledge and can reason about medical information across many domains, holding promising potential for diverse medical applications in the near future. In this study, we demonstrate a concerning vulnerability of LLMs in medicine. Through targeted manipulation of just 1.1% of the weights of the LLM, we can deliberately inject incorrect biomedical facts. The erroneous information is then propagated in the model's output while maintaining ...